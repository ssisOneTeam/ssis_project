{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 성능 비교"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 문서에 대해 여러개의 테스트 케이스(해당 문서에 관련한 질문)를 집어넣고 유사도 계산 때려보면 어떨지  \n",
    "이걸 응용해서 n개의 케이스를 평균때려 계산해서 써도 될듯??\n",
    "https://github.com/BM-K/Sentence-Embedding-is-all-you-need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "def cal_score(a, b):\n",
    "    if len(a.shape) == 1: a = a.unsqueeze(0)\n",
    "    if len(b.shape) == 1: b = b.unsqueeze(0)\n",
    "\n",
    "    a_norm = a / a.norm(dim=1)[:, None]\n",
    "    b_norm = b / b.norm(dim=1)[:, None]\n",
    "    return torch.mm(a_norm, b_norm.transpose(0, 1)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained('BM-K/KoSimCSE-roberta-multitask')  \n",
    "tokenizer = AutoTokenizer.from_pretrained('BM-K/KoSimCSE-roberta-multitask')  \n",
    "\n",
    "sentences = ['국민의 취업준비를 위한 국민내일배움카드제가 개설되었다.', # 기존 문서\n",
    "             '국민내일배움카드제가 국민의 취준을 돕고 있다.', # 검색 쿼리\n",
    "             '나는 밥을 먹었다.'] # 관련없는 쿼리\n",
    "\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "embeddings, _ = model(**inputs, return_dict=False)\n",
    "\n",
    "score01 = cal_score(embeddings[0][0], embeddings[1][0])  # 87.2708\n",
    "# '국민의 취업준비를 위한 국민내일배움카드제가 개설되었다.' @ '국민내일배움카드제가 국민의 취준을 돕고 있다.'\n",
    "score02 = cal_score(embeddings[0][0], embeddings[2][0])  # 13.7799\n",
    "# '국민의 취업준비를 위한 국민내일배움카드제가 개설되었다.' @ '나는 밥을 먹었다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[87.2708]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[13.7799]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score02"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## finetuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'your_model_path'\n",
    "model = AutoModel.from_pretrained(PATH)  \n",
    "tokenizer = AutoTokenizer.from_pretrained(PATH)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['국민의 취업준비를 위한 국민내일배움카드제가 개설되었다.',\n",
    "             '국민내일배움카드제가 국민의 취준을 돕고 있다.',\n",
    "             '나는 밥을 먹었다.']\n",
    "\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "embeddings, _ = model(**inputs, return_dict=False)\n",
    "\n",
    "score01 = cal_score(embeddings[0][0], embeddings[1][0])  # 90.5397\n",
    "# '국민의 취업준비를 위한 국민내일배움카드제가 개설되었다.' @ '국민내일배움카드제가 국민의 취준을 돕고 있다.'\n",
    "score02 = cal_score(embeddings[0][0], embeddings[2][0])  # -1.1663\n",
    "# '국민의 취업준비를 위한 국민내일배움카드제가 개설되었다.' @ '나는 밥을 먹었다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[90.5397]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1663]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['20대',\n",
    "             '18세에서 34세',\n",
    "             '나는 밥을 먹었다.']\n",
    "\n",
    "inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "embeddings, _ = model(**inputs, return_dict=False)\n",
    "\n",
    "score01 = cal_score(embeddings[0][0], embeddings[1][0])  # 90.5397\n",
    "# '국민의 취업준비를 위한 국민내일배움카드제가 개설되었다.' @ '국민내일배움카드제가 국민의 취준을 돕고 있다.'\n",
    "score02 = cal_score(embeddings[0][0], embeddings[2][0])  # -1.1663\n",
    "# '국민의 취업준비를 위한 국민내일배움카드제가 개설되었다.' @ '나는 밥을 먹었다.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[46.0533]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score01"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdf-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
